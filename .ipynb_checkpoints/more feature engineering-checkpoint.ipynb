{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOrig = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOrig['type'] = 'train'\n",
    "test['type'] = 'val'\n",
    "\n",
    "appended = pd.concat([trainOrig,test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended.PassengerId.duplicated().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with data\n",
    "def manipulateData(train):\n",
    "    # replace all the Nan  (Age, cabin, embarked)\n",
    "    train['Age'].isnull().values.any()\n",
    "\n",
    "    train['Age'] = train.Age.fillna(0)\n",
    "    train['Age'] = train.Age.replace(0, train.Age.mean())\n",
    "\n",
    "    # S = 0, C = 1, Q = 2\n",
    "    train['Embarked'] = train.Embarked.replace('S', 0)\n",
    "    train['Embarked'] = train.Embarked.replace('C', 1)\n",
    "    train['Embarked'] = train.Embarked.replace('Q', 2)\n",
    "    train['Embarked'] = train.Embarked.fillna(train.Embarked.mean())\n",
    "\n",
    "    # encode the cabin and ticket\n",
    "    i = -1\n",
    "    for cabin in train.Cabin.unique():\n",
    "        train['Cabin'] = train.Cabin.replace(cabin, i)\n",
    "        i = i + 1 \n",
    "\n",
    "    i = 0\n",
    "    for ticket in train.Ticket.unique():\n",
    "        train['Ticket'] = train.Ticket.replace(ticket, i)\n",
    "        i = i + 1 \n",
    "\n",
    "    #encode the gender\n",
    "    train['Sex'] = train.Sex.replace('male', 0)\n",
    "    train['Sex'] = train.Sex.replace('female', 1)\n",
    "\n",
    "    #conde Mr, Mrs, Miss and last names\n",
    "    i = 0\n",
    "    lastName = []\n",
    "    title = []\n",
    "    for name in train['Name'].to_numpy():\n",
    "        foundLastName = False\n",
    "        foundM = False\n",
    "        foundTitle = False\n",
    "        indexM = 0\n",
    "        j = 0\n",
    "        for letter in name:\n",
    "            if letter == ',':\n",
    "                #train['LastName'] = name[0:j]\n",
    "                lastName.append(name[0:j])\n",
    "                foundLastName = True\n",
    "            if foundLastName and (letter == 'M' or letter == 'D' or letter == 'R' or letter == 'L' or letter == 'S' or letter == 'C' or letter == 't' or letter == 'J'):\n",
    "                foundM = True\n",
    "                indexM = j\n",
    "            if foundM and letter == '.':\n",
    "                if foundTitle:\n",
    "                    print(name)\n",
    "                else:\n",
    "                    title.append(name[indexM:j])\n",
    "                foundTitle = True\n",
    "            j = j+1\n",
    "        if not foundTitle:\n",
    "            print(name)\n",
    "        i = i+1\n",
    "\n",
    "    train['Title'] = title\n",
    "    train['LastName'] = lastName\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for LastName in train.LastName.unique():\n",
    "        train['LastName'] = train.LastName.replace(LastName, i)\n",
    "        i = i + 1 \n",
    "\n",
    "    i = 0\n",
    "    for Title in train.Title.unique():\n",
    "        train['Title'] = train.Title.replace(Title, i)\n",
    "        i = i + 1 \n",
    "    \n",
    "    # encode the fare and the ticket (normalize)\n",
    "    #train['Fare'] = (train.Fare - train.Fare.mean()) / (train.Fare.max()-train.Fare.min())\n",
    "    #train['Ticket'] = (train.Ticket - train.Ticket.mean()) / (train.Ticket.max()-train.Ticket.min())\n",
    "    #train['LastName'] = (train.LastName - train.LastName.mean()) / (train.LastName.max()-train.LastName.min())\n",
    "    #train['Age'] = (train.Age - train.Age.mean()) / (train.Age.max()-train.Age.min())\n",
    "\n",
    "    train = train.drop(['Name'], axis = 1)\n",
    "    train = train.drop(['PassengerId'], axis = 1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulatedData = manipulateData(appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulatedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_manipulated = manipulatedData.loc[manipulatedData.type == 'train']\n",
    "X_train = training_data_manipulated.drop(['Survived', 'type'], axis = 1)\n",
    "Y_train = training_data_manipulated.Survived\n",
    "\n",
    "val_data_manipulated = manipulatedData.loc[manipulatedData.type == 'val']\n",
    "X_val = val_data_manipulated.drop(['Survived','type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline model (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=1000,random_state=0, max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LastName\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "LastName = RandomForestClassifier(random_state=0)\n",
    "LastName.fit(X_train[features], y_train)\n",
    "print(LastName.score(X_train[features],y_train))\n",
    "print(LastName.score(X_test[features],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "y_test_np = y_test.to_numpy()\n",
    "indexes = []\n",
    "for i in range(0,len(pred)):\n",
    "    if(pred[i] !=y_test_np[i]):\n",
    "        indexes.append(i)\n",
    "        print('pred', pred[i], ' truth', y_test_np[i])\n",
    "        #print(X_test.iloc[i])\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest on diff features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class\n",
    "cass = RandomForestClassifier(random_state=0)\n",
    "cass.fit(np.reshape(X_train['Pclass'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(cass.score(np.reshape(X_train['Pclass'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(cass.score(np.reshape(X_test['Pclass'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sex\n",
    "sex = RandomForestClassifier(random_state=0)\n",
    "sex.fit(np.reshape(X_train['Sex'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(sex.score(np.reshape(X_train['Sex'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(sex.score(np.reshape(X_test['Sex'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age\n",
    "age = RandomForestClassifier(random_state=0)\n",
    "age.fit(np.reshape(X_train['Age'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(age.score(np.reshape(X_train['Age'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(age.score(np.reshape(X_test['Age'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SibSp\n",
    "SibSp = RandomForestClassifier(random_state=0)\n",
    "SibSp.fit(np.reshape(X_train['SibSp'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(SibSp.score(np.reshape(X_train['SibSp'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(SibSp.score(np.reshape(X_test['SibSp'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parch\n",
    "Parch = RandomForestClassifier(random_state=0)\n",
    "Parch.fit(np.reshape(X_train['Parch'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Parch.score(np.reshape(X_train['Parch'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Parch.score(np.reshape(X_test['Parch'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket\n",
    "Ticket = RandomForestClassifier(random_state=0)\n",
    "Ticket.fit(np.reshape(X_train['Ticket'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Ticket.score(np.reshape(X_train['Ticket'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Ticket.score(np.reshape(X_test['Ticket'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare\n",
    "Fare = RandomForestClassifier(random_state=0)\n",
    "Fare.fit(np.reshape(X_train['Fare'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Fare.score(np.reshape(X_train['Fare'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Fare.score(np.reshape(X_test['Fare'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cabin\n",
    "Cabin = RandomForestClassifier(random_state=0)\n",
    "Cabin.fit(np.reshape(X_train['Cabin'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Cabin.score(np.reshape(X_train['Cabin'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Cabin.score(np.reshape(X_test['Cabin'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "Embarked = RandomForestClassifier(random_state=0)\n",
    "Embarked.fit(np.reshape(X_train['Embarked'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Embarked.score(np.reshape(X_train['Embarked'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Embarked.score(np.reshape(X_test['Embarked'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "Title = RandomForestClassifier(random_state=0)\n",
    "Title.fit(np.reshape(X_train['Title'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Title.score(np.reshape(X_train['Title'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Title.score(np.reshape(X_test['Title'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LastName\n",
    "LastName = RandomForestClassifier(random_state=0)\n",
    "LastName.fit(np.reshape(X_train['LastName'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(LastName.score(np.reshape(X_train['LastName'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(LastName.score(np.reshape(X_test['LastName'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputFeatures = X_train.shape[1]\n",
    "activation = \"relu\"\n",
    "size = 100\n",
    "X_input = Input(shape=(n_inputFeatures,))\n",
    "\n",
    "X = Dense(10, activation=activation)(X_input)\n",
    "#X = Dense(60, activation=activation)(X)\n",
    "# X = Dense(20, activation=activation)(X)\n",
    "\n",
    "X = Dense(1, activation=\"sigmoid\")(X)\n",
    "\n",
    "# Create model\n",
    "nn = Model(inputs = X_input, outputs = X, name='deepNN')\n",
    "\n",
    "optAdam = tf.keras.optimizers.Adam()\n",
    "nn.compile(optimizer=optAdam, loss='binary_crossentropy', metrics='binary_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn.fit(X_train, y_train, epochs = 500, batch_size = 100000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 - 30 nn for 1000 epochs (overfitted at around 400, best test acc = 0.8475) loss: 0.2809 - binary_accuracy: 0.8742 - val_loss: 0.4978 - val_binary_accuracy: 0.8305\n",
    "#10 -10 nn for 1000 epochs (overfitted around 600, best acc = 0.8169)\n",
    "#100 -100 nn for 1000 epochs (overfitted around 150, best acc = 0.8407)\n",
    "# 60-30-10 nn for 1000 epochs (overfitted around 250, best acc = 0.8339)\n",
    "training_loss = history.history['loss']\n",
    "val_loss      = history.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, val_loss, 'g--')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosted tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalset = [(X_train, y_train), (X_test, y_test)]\n",
    "boostedTree = XGBClassifier(learning_rate=0.1, n_estimators = 100)\n",
    "boostedTree.fit(X_train, y_train,  eval_set=evalset, early_stopping_rounds=5)\n",
    "\n",
    "print(boostedTree.score(X_train, y_train))\n",
    "print(boostedTree.score(X_test, y_test))\n",
    "#learning rate 0.1, best logloss = 0.425 (30 steps, 5 steps early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, verbose = 1, n_init = 2, tol = 1e-26, precompute_distances = True).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "print(logReg.score(X_train,y_train))\n",
    "print(logReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "estimators = [('rf1', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "              ('rf2', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "              ('rf3', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "              ('rf4', RandomForestClassifier(n_estimators=4, random_state=42)),\n",
    "              ('xgboost1', XGBClassifier(learning_rate=0.1, max_depth=10, random_state=42)),\n",
    "              ('xgboost2', XGBClassifier(learning_rate=0.1, max_depth=8, random_state=42)),\n",
    "              ('xgboost3', XGBClassifier(learning_rate=0.1, max_depth=6, random_state=42)),\n",
    "              ('xgboost4', XGBClassifier(learning_rate=0.1, max_depth=4, random_state=42)),\n",
    "              #('svr', make_pipeline(StandardScaler(),LinearSVC(random_state=42))),\n",
    "              ('nn1', MLPClassifier(hidden_layer_sizes = (10,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              ('nn2', MLPClassifier(hidden_layer_sizes = (100,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              ('nn3', MLPClassifier(hidden_layer_sizes = (10, 10,10,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              #('logReg', LogisticRegression()),\n",
    "            # ('kmeans', make_pipeline(StandardScaler(),KMeans(random_state=42))),\n",
    "              \n",
    "             ]\n",
    "\n",
    "clf = StackingClassifier(\n",
    "     estimators=estimators, final_estimator=LogisticRegression()\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
