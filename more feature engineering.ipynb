{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOrig = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOrig['type'] = 'train'\n",
    "test['type'] = 'val'\n",
    "\n",
    "appended = pd.concat([trainOrig,test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended.PassengerId.duplicated().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with data\n",
    "def manipulateData(train):\n",
    "    # replace all the Nan  (Age, cabin, embarked)\n",
    "    train['Age'].isnull().values.any()\n",
    "    ageMean = train.Age.mean()\n",
    "    train['Age'] = train.Age.fillna(0)\n",
    "    train['Age'] = train.Age.replace(0, ageMean)\n",
    "    train['Age'] = train['Age'].astype(int)\n",
    "    \n",
    "#     fareMean = train.Fare.mean()\n",
    "#     train['Fare'] = train.Fare.fillna(0)\n",
    "#     train['Fare'] = train.Fare.replace(0, fareMean)\n",
    "#     train['Fare'] = train['Fare'].astype(int)\n",
    "    train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
    "    train.loc[ train['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    train.loc[(train['Fare'] > 7.91) & (train['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    train.loc[(train['Fare'] > 14.454) & (train['Fare'] <= 31), 'Fare']   = 2\n",
    "    train.loc[ train['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    train['Fare'] = train['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    train.loc[ train['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    train.loc[(train['Age'] > 16) & (train['Age'] <= 32), 'Age'] = 1\n",
    "    train.loc[(train['Age'] > 32) & (train['Age'] <= 48), 'Age'] = 2\n",
    "    train.loc[(train['Age'] > 48) & (train['Age'] <= 64), 'Age'] = 3\n",
    "    train.loc[ train['Age'] > 64, 'Age'] = 4 ;\n",
    "\n",
    "    # S = 0, C = 1, Q = 2\n",
    "    train['Embarked'] = train.Embarked.replace('S', 0)\n",
    "    train['Embarked'] = train.Embarked.replace('C', 1)\n",
    "    train['Embarked'] = train.Embarked.replace('Q', 2)\n",
    "    print(train.Embarked.mean())\n",
    "    train['Embarked'] = train.Embarked.fillna(train.Embarked.mean())\n",
    "\n",
    "    # encode the cabin and ticket\n",
    "    train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    i = -1\n",
    "    for cabin in train.Cabin.unique():\n",
    "        train['Cabin'] = train.Cabin.replace(cabin, i)\n",
    "        i = i + 1\n",
    "\n",
    "    peopleInCabin =[]\n",
    "    for cabin in train.Cabin:\n",
    "        if cabin >= 0:\n",
    "            peopleInCabin.append(train.loc[train.Cabin == cabin].shape[0])\n",
    "        else:\n",
    "            peopleInCabin.append(0)\n",
    "    train['people_in_cabin'] = peopleInCabin\n",
    "\n",
    "    i = 0\n",
    "    for ticket in train.Ticket.unique():\n",
    "        train['Ticket'] = train.Ticket.replace(ticket, i)\n",
    "        i = i + 1 \n",
    "    sameTicket =[]\n",
    "    for ticket in train.Ticket:\n",
    "        if ticket >= 0:\n",
    "            sameTicket.append(train.loc[train.Ticket == ticket].shape[0])\n",
    "        else:\n",
    "            sameTicket.append(0)\n",
    "    train['same_ticket'] = sameTicket\n",
    "\n",
    "    #encode the gender\n",
    "    train['Sex'] = train.Sex.replace('male', 0)\n",
    "    train['Sex'] = train.Sex.replace('female', 1)\n",
    "\n",
    "    #conde Mr, Mrs, Miss and last names\n",
    "    i = 0\n",
    "    lastName = []\n",
    "    title = []\n",
    "    for name in train['Name'].to_numpy():\n",
    "        foundLastName = False\n",
    "        foundM = False\n",
    "        foundTitle = False\n",
    "        indexM = 0\n",
    "        j = 0\n",
    "        for letter in name:\n",
    "            if letter == ',':\n",
    "                #train['LastName'] = name[0:j]\n",
    "                lastName.append(name[0:j])\n",
    "                foundLastName = True\n",
    "            if foundLastName and (letter == 'M' or letter == 'D' or letter == 'R' or letter == 'L' or letter == 'S' or letter == 'C' or letter == 't' or letter == 'J'):\n",
    "                foundM = True\n",
    "                indexM = j\n",
    "            if foundM and letter == '.':\n",
    "                if foundTitle:\n",
    "                    print(name)\n",
    "                else:\n",
    "                    title.append(name[indexM:j])\n",
    "                foundTitle = True\n",
    "            j = j+1\n",
    "        if not foundTitle:\n",
    "            print(name)\n",
    "        i = i+1\n",
    "\n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        # If the title exists, extract and return it.\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "    # Create a new feature Title, containing the titles of passenger names\n",
    "    train['Title'] = train['Name'].apply(get_title)\n",
    "    # Group all non-common titles into one single grouping \"Rare\"\n",
    "    train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "    train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "    train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "        \n",
    "    #train['Title'] = title\n",
    "    train['LastName'] = lastName\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for LastName in train.LastName.unique():\n",
    "        train['LastName'] = train.LastName.replace(LastName, i)\n",
    "        i = i + 1 \n",
    "\n",
    "    sameLastName =[]\n",
    "    for LastName in train.LastName:\n",
    "        if LastName >= 0:\n",
    "            sameLastName.append(train.loc[train.LastName == LastName].shape[0])\n",
    "        else:\n",
    "            sameLastName.append(0)\n",
    "    train['same_last_name'] = sameLastName\n",
    "    \n",
    "    train['familySize'] = train.SibSp + train.Parch\n",
    "    \n",
    "    isAlone =[]\n",
    "    for familySize in train.familySize:\n",
    "        if familySize == 0:\n",
    "            isAlone.append(1)\n",
    "        else:\n",
    "            isAlone.append(0)\n",
    "    train['isAlone'] = isAlone\n",
    "    \n",
    "    i = 0\n",
    "    for Title in train.Title.unique():\n",
    "        train['Title'] = train.Title.replace(Title, i)\n",
    "        i = i + 1 \n",
    "    \n",
    "    # encode the fare and the ticket (normalize)\n",
    "    #train['Fare'] = (train.Fare - train.Fare.mean()) / (train.Fare.max()-train.Fare.min())\n",
    "    #train['Ticket'] = (train.Ticket - train.Ticket.mean()) / (train.Ticket.max()-train.Ticket.min())\n",
    "    #train['LastName'] = (train.LastName - train.LastName.mean()) / (train.LastName.max()-train.LastName.min())\n",
    "    #train['Age'] = (train.Age - train.Age.mean()) / (train.Age.max()-train.Age.min())\n",
    "\n",
    "    train = train.drop(['Name'], axis = 1)\n",
    "    train = train.drop(['PassengerId'], axis = 1)\n",
    "    train = train.drop(['Cabin'], axis = 1)\n",
    "    train = train.drop(['Ticket'], axis = 1)\n",
    "    train = train.drop(['SibSp'], axis = 1)\n",
    "    train = train.drop(['Parch'], axis = 1)\n",
    "    train = train.drop(['LastName'], axis = 1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulatedData = manipulateData(appended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulatedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivedAge = manipulatedData['Age'].loc[manipulatedData.Survived == 1]\n",
    "diedAge = manipulatedData['Age'].loc[manipulatedData.Survived == 0]\n",
    "\n",
    "survivedAge.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diedAge.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_manipulated = manipulatedData.loc[manipulatedData.type == 'train']\n",
    "X_train = training_data_manipulated.drop(['Survived', 'type'], axis = 1)\n",
    "Y_train = training_data_manipulated.Survived\n",
    "\n",
    "val_data_manipulated = manipulatedData.loc[manipulatedData.type == 'val']\n",
    "X_val = val_data_manipulated.drop(['Survived','type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline model (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)#, max_depth=10, n_estimators = 1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [ 200,300,400,500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=0), param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train,y_train)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1=RandomForestClassifier(random_state=0, n_estimators= 500, criterion = 'gini',max_features = 'auto',max_depth = 10)\n",
    "rfc1.fit(X_train, y_train)\n",
    "print(rfc1.score(X_train,y_train))\n",
    "print(rfc1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LastName\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "LastName = RandomForestClassifier(random_state=0)\n",
    "LastName.fit(X_train[features], y_train)\n",
    "print(LastName.score(X_train[features],y_train))\n",
    "print(LastName.score(X_test[features],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "y_test_np = y_test.to_numpy()\n",
    "indexes = []\n",
    "for i in range(0,len(pred)):\n",
    "    if(pred[i] !=y_test_np[i]):\n",
    "        indexes.append(i)\n",
    "        print('pred', pred[i], ' truth', y_test_np[i])\n",
    "        #print(X_test.iloc[i])\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest on diff features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class\n",
    "cass = RandomForestClassifier(random_state=0)\n",
    "cass.fit(np.reshape(X_train['Pclass'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(cass.score(np.reshape(X_train['Pclass'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(cass.score(np.reshape(X_test['Pclass'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sex\n",
    "sex = RandomForestClassifier(random_state=0)\n",
    "sex.fit(np.reshape(X_train['Sex'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(sex.score(np.reshape(X_train['Sex'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(sex.score(np.reshape(X_test['Sex'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age\n",
    "age = RandomForestClassifier(random_state=0)\n",
    "age.fit(np.reshape(X_train['Age'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(age.score(np.reshape(X_train['Age'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(age.score(np.reshape(X_test['Age'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SibSp\n",
    "SibSp = RandomForestClassifier(random_state=0)\n",
    "SibSp.fit(np.reshape(X_train['SibSp'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(SibSp.score(np.reshape(X_train['SibSp'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(SibSp.score(np.reshape(X_test['SibSp'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parch\n",
    "Parch = RandomForestClassifier(random_state=0)\n",
    "Parch.fit(np.reshape(X_train['Parch'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Parch.score(np.reshape(X_train['Parch'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Parch.score(np.reshape(X_test['Parch'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticket\n",
    "Ticket = RandomForestClassifier(random_state=0)\n",
    "Ticket.fit(np.reshape(X_train['Ticket'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Ticket.score(np.reshape(X_train['Ticket'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Ticket.score(np.reshape(X_test['Ticket'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare\n",
    "Fare = RandomForestClassifier(random_state=0)\n",
    "Fare.fit(np.reshape(X_train['Fare'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Fare.score(np.reshape(X_train['Fare'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Fare.score(np.reshape(X_test['Fare'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cabin\n",
    "Cabin = RandomForestClassifier(random_state=0)\n",
    "Cabin.fit(np.reshape(X_train['Cabin'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Cabin.score(np.reshape(X_train['Cabin'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Cabin.score(np.reshape(X_test['Cabin'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked\n",
    "Embarked = RandomForestClassifier(random_state=0)\n",
    "Embarked.fit(np.reshape(X_train['Embarked'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Embarked.score(np.reshape(X_train['Embarked'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Embarked.score(np.reshape(X_test['Embarked'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "Title = RandomForestClassifier(random_state=0)\n",
    "Title.fit(np.reshape(X_train['Title'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(Title.score(np.reshape(X_train['Title'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(Title.score(np.reshape(X_test['Title'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LastName\n",
    "LastName = RandomForestClassifier(random_state=0)\n",
    "LastName.fit(np.reshape(X_train['LastName'].to_numpy(),(X_train.shape[0],1)), y_train)\n",
    "print(LastName.score(np.reshape(X_train['LastName'].to_numpy(),(X_train.shape[0],1)),y_train))\n",
    "print(LastName.score(np.reshape(X_test['LastName'].to_numpy(),(X_test.shape[0],1)),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputFeatures = X_train.shape[1]\n",
    "activation = \"relu\"\n",
    "size = 100\n",
    "X_input = Input(shape=(n_inputFeatures,))\n",
    "\n",
    "X = Dense(10, activation=activation)(X_input)\n",
    "#X = Dense(60, activation=activation)(X)\n",
    "# X = Dense(20, activation=activation)(X)\n",
    "\n",
    "X = Dense(1, activation=\"sigmoid\")(X)\n",
    "\n",
    "# Create model\n",
    "nn = Model(inputs = X_input, outputs = X, name='deepNN')\n",
    "\n",
    "optAdam = tf.keras.optimizers.Adam()\n",
    "nn.compile(optimizer=optAdam, loss='binary_crossentropy', metrics='binary_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn.fit(X_train, y_train, epochs = 500, batch_size = 100000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 - 30 nn for 1000 epochs (overfitted at around 400, best test acc = 0.8475) loss: 0.2809 - binary_accuracy: 0.8742 - val_loss: 0.4978 - val_binary_accuracy: 0.8305\n",
    "#10 -10 nn for 1000 epochs (overfitted around 600, best acc = 0.8169)\n",
    "#100 -100 nn for 1000 epochs (overfitted around 150, best acc = 0.8407)\n",
    "# 60-30-10 nn for 1000 epochs (overfitted around 250, best acc = 0.8339)\n",
    "training_loss = history.history['loss']\n",
    "val_loss      = history.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, val_loss, 'g--')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosted tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalset = [(X_train, y_train), (X_test, y_test)]\n",
    "boostedTree = XGBClassifier(learning_rate=0.1,# n_estimators = 100)\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1)\n",
    "boostedTree.fit(X_train, y_train,  eval_set=evalset, early_stopping_rounds=50)\n",
    "\n",
    "print(boostedTree.score(X_train, y_train))\n",
    "print(boostedTree.score(X_test, y_test))\n",
    "#learning rate 0.1, best logloss = 0.425 (30 steps, 5 steps early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, verbose = 1, n_init = 2, tol = 1e-26, precompute_distances = True).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "print(logReg.score(X_train,y_train))\n",
    "print(logReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "estimators = [('rf1', RandomForestClassifier(n_estimators = 100,max_depth=10, random_state=42)),\n",
    "              ('rf2', RandomForestClassifier(n_estimators = 100,max_depth=2, random_state=42)),\n",
    "              ('rf3', RandomForestClassifier(n_estimators = 100,max_depth=6, random_state=42)),\n",
    "              ('rf4', RandomForestClassifier(n_estimators = 100,max_depth=4, random_state=42)),\n",
    "              ('xgboost1', XGBClassifier(objective= 'binary:logistic',learning_rate=0.1, max_depth=10, random_state=42)),\n",
    "              ('xgboost2', XGBClassifier(objective= 'binary:logistic',learning_rate=0.1, max_depth=8, random_state=42)),\n",
    "              ('xgboost3', XGBClassifier(objective= 'binary:logistic',learning_rate=0.1, max_depth=6, random_state=42)),\n",
    "              ('xgboost4', XGBClassifier(objective= 'binary:logistic',learning_rate=0.1, max_depth=4, random_state=42)),\n",
    "              #('svr', make_pipeline(StandardScaler(),LinearSVC(random_state=42))),\n",
    "              ('nn1', MLPClassifier(hidden_layer_sizes = (10,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              ('nn2', MLPClassifier(hidden_layer_sizes = (50,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              ('nn3', MLPClassifier(hidden_layer_sizes = (50, 30,10,),random_state=42, max_iter=500, early_stopping=True)),\n",
    "              ('logReg', LogisticRegression()),\n",
    "            # ('kmeans', make_pipeline(StandardScaler(),KMeans(random_state=42))),\n",
    "              \n",
    "             ]\n",
    "\n",
    "clf = StackingClassifier(\n",
    "     estimators=estimators, final_estimator=LogisticRegression()\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
